---
layout: page
title: Statistical Analysis 
order: 9
session: 3
length: 60
toc: true
adapted: false
attrib_name: Programming with R
attrib_link: https://github.com/swcarpentry/r-novice-inflammation
attrib_copywrite: Software Carpentry
attrib_license: CC-BY 4.0
attrib_license_link: https://creativecommons.org/licenses/by/4.0/
---


```{r, echo = FALSE}
bp_dataset <- read.csv(file = "../data/bp_dataset_session4.csv", header = TRUE)
```


R is synmomous with data analysis. Here we will learn how to perform a number of common statistical tests with R. Please note that the focus here is on how
to perform a given test in R, it is not to discuss the merits of or scenarios in which you would use a specific test.

# Loading the dataset

To do statistics we need some observed data. We will use a dataset contained in the csv file [bp_dataset.csv](../data/bp_dataset_session4.csv). This dataset is based on a clinical trial to test the effect of two 
drugs (Drug A and Drug B), compared with an inactive control drug (placebo), on blood pressure in people who have high blood pressure. The purpose of the 
drugs is to reduce blood pressure. Some additional information about the people in the trial, such as their age and sex, is also provided (see 
[codebook](../data/bp_dataset_codebook_session4.xlsx) for further information about the variables).

Let's start by loading the dataset. You need to ensure that the dataset is located in your current working directory. 
We will read in the csv file and assign it to a variable called ```bp_dataset```. The ```header=TRUE``` argument means R will take the entries in the first row 
 and use these to set the column headings. 

```{r, eval = FALSE}
bp_dataset<-read.csv(file="bp_dataset_session4.csv", header=TRUE)
```

Take a look at the column heads.

```{r}
head(bp_dataset)
```

Let's find out how many rows (observations) and variables (columns) are in this dataset using the ```dim``` command (for dimensions).

```{r}
dim(bp_dataset)
```


<details>
	<summary> Data Organisation </summary>
	<pre>
		
When it comes to programming how you organise/store your data becomes important to facilitate efficient processing. This is beyond the
remit of this course - but you can find out more about the principles of [tidy data here](https://r4ds.had.co.nz/tidy-data.html).

    </pre>
</details>

We also want to check the types of variable in the dataframe. The 'str' command allows us to check the structure of the dataframe and tells us 
about the types of variables in our dataset.

```{r}
str(bp_dataset)
```

In this dataset we have both integer and character variables. Gender is provided as a binary, indicator or dummary variable called ```male``` coded as 0 
(for female) and 1 (for male). This is not nessecary, if it was coded as a factor with the levels "Female" and "Male" R would be happy to use in the 
statistical functions. Coding it in this way however, is more aligned with how it is used in statistics, and may make interpetation easier. 

The variable `intervention` is a character variable.


# Summary statistics

In this dataset, there are 4 numeric variables. These are ```age```, and blood pressure measured at three timepoints (```bp_baseline```, 
```bp_3m```, ```bp_6m```).

We want to find the mean, median, standard deviation and variance for these variables. Let's start with the mean. To find the mean for ```age``` we can use:

```{r}
mean(bp_dataset$age)
```

We can attach the dataframe ```bp_dataset```, so we don't need to use the ```$``` notation for each command. Remember to use the ```detach()``` 
command when you wish to detach the dataframe.

```{r}
attach(bp_dataset)
mean(age)
```

We can also calculate the median, standard deviation, variance, minimum, maximum, range and sum fairly easily using base R functions. 


```{r}
sd(age)
median(age)
var(age)
min(age)
max(age)
range(age)
sum(age)
```

*Note* The commands 'sd' and 'var' calculate the sample sd and variance, not the population sd and variance.

We can also calculate percentiles. Using the ```quantile()``` command we need to specify which quantiles ( as proportions) that we want to calculate,
where the 0.5 quantile would represent the median.

```{r}
quantile(age, probs = c(.25, .5, .75))
```

To get the inter-quartile range (75th percentile minus 25th percentile) we can do this with the ```IQR()``` function.

```{r}
IQR(age)
```

We can also calculate multiple descriptive summary statistics of a numeric variable simultaneously using the function ```summary()```.

```{r}
summary(age)
```

## Activity

Find the means, medians and range for the variable ```bp_baseline``` and ```bp_3m```.

# Summary statistics by groups

We can calculate statistics for different subsets or groups of the data by using R command ```tapply()```. The ```tapply()``` 
command requires 3  arguments :

 + a numeric variable which we want to summarise (in the example below this is ```age```) 
 + a categorical variable indicating the subgroups,which we want to group by (in the example below this is ```male```)
 + the function we wish to call on each subgroup (in the example below this is ```mean```)

```{r}
tapply(age, male, mean)
```

If we want to calculate a summary statistics for a sub group, by subsetting it and providing the subset to the ```mean()``` function. For example 
to calucate the mean of just the means (i.e where male==1). 
Note the use of ```==``` for specifiying an equality condition.


```{r}
mean(age[male==1])
```


We can use the ```tapply()``` function to calculate the medians for the intervention groups.

```{r}
tapply(age, intervention, median)
```

If we want to calculate summary statistics for combinations of groups for example by sex and intervention group, we can use the ```aggregate()```
 command. We use the formula method to specify which variables we want summarise (on the left hand side of the ~) and which we want to group by
 (on the right hand side of the ~).  If all the variables are included in
 single data.frame, we can construct the formula using just the column names, and include the argument ```data``` to specify which object these are found
 in. The ```FUN``` argument specfies which function you want to apply to these data, which is the mean in this example. 
 Note that we need to include the dataset as an argument, even though we have attached ```bp_dataset```.


```{r}
aggregate(age ~ male + intervention, data=bp_dataset, FUN=mean)
```

```{r}
aggregate(age, bp_baseline ~ male + intervention, data=bp_dataset, FUN=mean)
```

## Activity

Calculate the mean, SD, median, 10th and 90th percentiles for `bp_baseline` for each intervention group. 
Also calculate the 25th centile, 50th centile (median) and 75th centile for `age`, for each combination of sex and intervention group. 


# Summary statistics for categorical data

We can create a frequency table for categorical variables using the ```table()``` command.

```{r}
table(male)
```

We can also produce cross-tabulations for two categorical variables. In fact we can produce tables for more than 2 categorical variables. 

```{r}
table(male, intervention)
```


If we also wish to calculate proportions or percentages, we can use the ```prop.table()``` command. We first need to create the 
table and then pass to ```prop.table()```. Youcan either do this in two stages:

```{r}
table.male<-table(male)
prop.table(table.male)
```

Or as a nested function call:

```{r}
prop.table(table(male, intervention))
```

We can also create a table for a subgroup of the data by providing just a subset of the data to the ```table()``` function.
 For example to count the number of each sex, only for people aged over 50:

```{r}
table(male[age>50])
```


## Activity 
Create table of frequencies and a table of percentages for each intervention group.

Create table of frequencies and a table of percentages for intervention group stratified by whether their baseline blood pressure is 
greater than or equal to 180.

# Common statistical tests: One-sample t-test

There are several types of t-test. We will start with the simplest: a one-sample 2-sided t-test to test the null hypothesis that the true mean 
value of a continuous variable is equal to a pre-specified value. The default behaviour, and the most common application is to compare to a value of 0.

```{r}
t.test(age)
```


We can see in the console, we get a more verbose output than we have seen before. Mainly because the result of statistical test often includes multiple
statistics, and the orginial writers of the ```t.test()``` function have made an effort to present these back to the user in an easy to intepret way. 

We can see there is a statement at the top of the output reminding or confirming which statistical test we have performed, and underneath this a confirmation
of which variable/data this was performed on. 

We then have a line of multiple test statistics, including the p-value. Here we can see our test result is highly significant with p < 2.2e-16. Given 
we are analysing a population of adults, they are all a lot older than 0 so it is not surprising. The function writers hhave take the executive decision
to report the p-value as < 2.2e-16 rather than give the specific value. In some fields/journals/research group, this approximation is not good enough. 
Later we will show you how to extract a more precise p-value. 

Underneath this we have a confirmation of the alternative hypothesis the statistic was considered against, we then have the confidence interval and the 
estimated mean of the sample.

We can vary the width of the confidence interval provided as part of the t-test output, by including the argument ```conf.int```. The default is 95% CI.
For the 90% confidence interval, we can run

```{r}
t.test(age, conf.level=0.90)
```

Here we can see that the majority of the output is unchanged, it is just the confidence interval which is different. 

The default behaviour is to perform a two-sided t-test. We can specify a one-sided t-test testing whether the true mean of the variable is greater than 
or less than the specified value  by including the argument ```alternative``` and setting it to either ```greater``` or ```less```. To test 
whether the true mean `age` is greater than 0 we use:

```{r}
t.test(age, alternative="greater")
```

Although this is a very uncommon application (due to the need to justify the choice of value), you can perform a one sample t-test against a value 
other than 0 by including the argument ```mu```. For example, we can use a t-test to test if true mean ```age```=50.

```{r}
t.test(age, mu=50)
```

If you are only performing one (or a few) statistical tests, and you are working interatively then you might be ok to manually copy the result from the 
console. However, there are likely times when you want to extract the result from the test for further processing, for example enter it into a table to 
save to your computer. We can save the output of a t.test (or indeed any other staistical test or function) to a variable, meaning we can manipulate it 
further.


```{r}
t.out<-t.test(age, mu=50)
t.out
```

As before, when we defined or created a variable, there is no output to the console. We can see the output by entering the name of the object. Let's 
explore the object that we have created. If we use ```class()``` we can learn what type of object it is.

```{r}
class(t.out)
```

```htest``` - that's a new one. This is a type of object that has been specfying defined to hold the result of a t-test. It consists of different objects
or slots where didferent parts of the result are stored. We can get a list of this elements with the function ```names()```

```{r}
names(t.out)
```

We can see 10 items listed. All of these are named elements stored within our ```htest``` object which we can extract by name using the ```$```. For example 
we can get just the p-value as follows:

```{r}
t.out$p.value
```

We can get the estimated mean:

```{r}
t.out$estimate
```

We can get the confidence interval:

```{r}
t.out$conf.int
class(t.out$conf.int)
```

While the p-value and estimated mean were single values, the confindence interval has returned a vector of length 2. 

# Common statistical tests: Two-sample unpaired t-test

The two-sample unpaired t-test, also known as an independent sample t-test, is used to compare the mean values of a continuous variable for two independent 
groups where the data points across the two groups are not matched or paired in any way. 

In this example, we want to compare the mean age between males and females, or in other words we want to test whether the true mean age is equal 
for males and females.

As we have all the data for our response variable (also called outcome variable or dependent variable), age in one object and we have a second object 
which indicates which enties are female and which are male, we will use the formula method for specifying the comparision we want to make. 

```{r}
t.test(age~male)
```

The output looks very similar to the output for the one sample t-test, with a couple of simple changes. 

1. The name of the test has changed to "Two Sample t-test"




The default behaviour the ```t.test()``` function is to assumes unequal variance.
We can also use a factor variable to indicate the two groups (i.e. as opposed to an integer variable with groups coded as numbers).

```{r}
t.test(age~male_factor)
```

We can test for equal variance by using a statistical test called an F test. The null hypothesis for this test is that variances are equal. To compare the variance of `age` by `male`:

```{r}
var.test(age ~ male)
```

An alternative statistical test to test for equal variances is Bartlett's test (again, the null hypothesis assumes that variances are equal for each group):

```{r}
bartlett.test(age ~ male)
```

If we wish to repeat the t-test using the assumption of equal variance:

```{r}
t.test(age~male, var.equal=TRUE)
```

### Paired t-test: comparing pairs of matched values

A paired t-test is used to compare two variables that are matched or paired in some way, for examples, measurements made on the same person at two different times. The paired t-test uses the differences between matched pairs of measurements to test whether the true means are equal.

For example, we may wish to perform a paired- t-test to test whether the true mean values for BP at baseline (`bp_baseline`) and BP at 3 months (`bp_3m`) are the same, taking into account that each person has their blood pressure measured at both baseline and 3 months, i.e. each measurement at baseline has a 'matched' measurement at 3 months taken in the same person.


```{r}
t.test(bp_3m,bp_baseline,paired=TRUE)
```

Note that the results are different if we do not
take into account the paired nature of the variables.

```{r}
t.test(bp_3m,bp_baseline,paired=FALSE)
```

<br>

#### Task 14
Perform a single sample 2-sided t-test to test whether the true mean of baseline BP is equal to 170. 
<br>

Repeat for test of whether true mean of baseline BP is equal to 180.<br>

Repeat for a 1-sided t-test of whether true mean of baseline BP is greater than 185.

<br>


#### Task 15
Perform an unpaired t-test to compare mean BP at 3 months between Drug A and the control group. Hint: use the ! symbol to indicate a logical statement about intervention.

<br>

Do the same to compare mean BP at 3 months between Drug B vs control, and between Drug B vs Drug A.

<br>


#### Task 16
Perform a paired t-test to test the null hypothesis that mean difference is 0 comparing BP at 6 months with BP at baseline.
<br>

Repeat to compare BP at 6 months with BP at 3 months for women (male=0) only.

***

